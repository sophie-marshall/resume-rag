{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG System Testing \n",
    "\n",
    "Now that we have our database set up (see `database-setup` notebook) and populated (see `pipeline-testing` notebook), we're ready to start developing our retrieval and generation components!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval \n",
    "\n",
    "We'll compare and contrast 3 retrieval methods:\n",
    "- Semantic search using `pgvector`'s built in similarity search functionality\n",
    "- Lexical search\n",
    "- Hybrid search (with and without tags) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "\n",
    "sys.path.append(\"/Users/srmarshall/Desktop/code/personal/resume-rag/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.database import PgClient\n",
    "import os \n",
    "\n",
    "# instantiate client\n",
    "pg_client = PgClient(\n",
    "    pg_host = os.getenv(\"PG_HOST\"), \n",
    "    pg_user = os.getenv(\"PG_USER\"), \n",
    "    pg_password = os.getenv(\"PG_PASSWORD\"), \n",
    "    pg_db = \"resume_rag\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set query \n",
    "query = \"tell me about your education\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Search with `pgvector`\n",
    "\n",
    "Semantic searching allows us to ask questions of our data using natural language. Where lexical search uses a naieve direct string comparison to find and surface results, semantic search compares the meaning of phrases using vector operations allowing for more robust searching. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/srmarshall/.virtualenvs/rag/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# instantiate the model\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# generate query embedding\n",
    "query_embedding = model.encode(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use embeddings to search database\n",
    "semantic_results = pg_client.semantic_search(query_embedding, \"content_embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we print the results we see almost all results describe my educational background. Weather if be the actual degree I obtained, or the reason I decided to study that subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Query: tell me about your education\n",
      "\n",
      "Semantic Search Results: \n",
      "  1.) education i graduated from the university of wisconsin madison in may of 2022 with bachelors of science in economics with a mathematical emphasis and psychology coursework from both degrees are highly relevant to my current area of work i draw on knowledge of human cognition while working alongside\n",
      "  2.) now that embedding powered technology is on the rise similarly it enables me to quickly ingest new information and apply it to prototypes and projects education i graduated from the university of wisconsin madison in may of 2022 with degrees in psychology and economics with a mathematical emphasis\n",
      "  3.) and cutting edge research helps me contextualize and quickly apply new techniques and conecepts as they are published the mathematical coursework i completed as part of my economics degree is something i use almost daily statics and linear algebra are everywhere especially now that embedding\n",
      "  4.) emphasis i opted for the mathematical emphasis to further develop my analytical skills and set me up for a data focused career moving forward experience education analytics data analyst intern and part time research analyst january 2021 to june 2022 after a successful data analytics internship i\n",
      "  5.) working alongside machine learning engineers to engineer prompts for foundation models and generally keep up with research being done to move the artificial intelligence and machine learning space forward being able to draw the parallels between my existing cognitive science training and cutting\n"
     ]
    }
   ],
   "source": [
    "print(f\"User Query: {query}\\n\")\n",
    "\n",
    "# print results\n",
    "print(f\"Semantic Search Results: \")\n",
    "for index, item in enumerate(semantic_results):\n",
    "    print(f\"  {index + 1}.) {item[3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexical Search with `tsvector`\n",
    "\n",
    "`tsvector` is a data type provided in Postgres that allows us to store pre-processed documents for full-text searching. Read more about it [here](https://www.postgresql.org/docs/current/textsearch-intro.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use regular query and generated tsvector column to conduct full text searc\n",
    "lexical_results = pg_client.lexical_search(query, table=\"content_embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we would expect at least some results as our document corpus grows, this is an example of why lexical search alone may not get the job done. If we conducted just plain lexical search, we'd assume there are no relevant documents in our database! \n",
    "\n",
    "While this isnt the most accurate representation, it goes to show that semantic search can drastically out perform a plain text search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Query: tell me about your education\n",
      "\n",
      "Lexical Search Results: \n",
      "No results found.\n"
     ]
    }
   ],
   "source": [
    "print (f\"User Query: {query}\\n\")\n",
    "\n",
    "print(f\"Lexical Search Results: \")\n",
    "if len(lexical_results) > 0:\n",
    "    for index, item in enumerate(lexical_results):\n",
    "        print(f\"  {index + 1}.) {item[3]}\")\n",
    "else:\n",
    "    print(\"No results found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How Postgres breaks out our query might be negatively impacting our assessment of lexical search on its own. For now, especially with a small corpus of data, lets conduct a more targeted lexical search to see what we might get back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_word_lexical_results = pg_client.lexical_search(\"education\", table=\"content_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f\"User Query: {\"education\"}\\n\")\n",
    "\n",
    "print(f\"Lexical Search Results: \")\n",
    "if len(single_word_lexical_results) > 0:\n",
    "    for index, item in enumerate(lexical_results):\n",
    "        print(f\"  {index + 1}.) {item[3]}\")\n",
    "else:\n",
    "    print(\"No results found.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
